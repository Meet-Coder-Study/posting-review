## Locust 란?

Locust는 오픈 소스 부하 테스트 도구로, 사용자가 Python으로 시나리오를 작성하여 웹 애플리케이션의 성능을 측정할 수 있게 해줍니다. 이 도구는 이벤트 기반 모델을 사용하여 수천 명의 사용자를 시뮬레이션하고, 웹사이트나 API 서버에 대한 부하 테스트를 실시간으로 실행할 수 있습니다. Locust는 사용자 친화적인 웹 인터페이스를 제공하여 테스트의 진행 상황을 모니터링하고, 결과를 분석할 수 있게 합니다.

## Locust 설치

```bash
$ pip install locust
```

pip를 통해서 `locust`를 설치합니다.

```pycon
from locust import HttpUser, task, constant
import random

class HelloWorldUser(HttpUser):
    wait_time = constant(1)  # 모든 요청 사이에 1초의 고정된 대기 시간 설정
    host = "http://localhost:8080"  # 테스트 대상 호스트 주소 지정

    @task
    def hello_world(self):
        self.client.get(
            "/api/v1/orders",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/orders"
        )
```

간단하게 HTTP GET 요청을 보내는 Locust 스크립트를 작성해보았습니다. `HttpUser` 클래스를 상속받아 사용자 클래스를 정의하고, `@task` 데코레이터를 사용하여 테스트 함수를 정의합니다. `self.client.get` 메서드를 사용하여 GET 요청을 보내고, `params`와 `name` 매개변수를 사용하여 요청 파라미터와 요청 이름을 설정합니다.

```bash
$ locust -f <file_name.py>
```

`locust` 명령어를 사용하여 Locust 스크립트를 실행합니다. `-f` 옵션을 사용하여 실행할 스크립트 파일을 지정합니다. 실행 후 웹 브라우저에서 `http://localhost:8089`로 접속하여 Locust 웹 인터페이스를 확인할 수 있습니다. 만약 파일명을 `locustfile.py` 으로 지정했다면 `locust` 명령어만 수행하면 됩니다.

## Locust의 특징

API 서버 성능 테스트 도구로 많이 알려진 도구들 중 JMeter와 nGrinder는 강력한 기능과 세밀한 설정 옵션으로 널리 사용되고 있습니다. 이러한 도구들은 복잡한 시나리오를 구현하고 대규모의 부하 테스트를 수행할 수 있는 뛰어난 능력을 가지고 있습니다. 그러나 이러한 기능성과 다양성이 더 간편하고 신속한 테스트 실행을 선호하는 사용자들에게는 설정과 실행 과정에서의 복잡성으로 인해 접근성이 떨어질 수 있습니다.

이에 비해 Locust는 사용자 친화적인 API 서버 성능 테스트 도구로, 그 사용의 용이성과 편리함에서 큰 장점을 가지고 있습니다. 특히, Locust는 Python으로 테스트 스크립트를 작성하기 때문에, 기존에 Python을 사용해본 경험이 있는 개발자라면 누구나 쉽게 접근할 수 있습니다. 이는 테스트 스크립트의 작성과 수정을 매우 간단하게 만들어 줍니다.

Locust의 설치 및 운용의 용이성은 테스트 프로세스를 대폭 단순화시킵니다. 몇 가지 간단한 명령어로 Locust를 설치할 수 있으며, 별도의 복잡한 설정 없이도 로컬 환경에서 바로 부하 테스트를 시작할 수 있습니다. 이러한 점은 개발 초기 단계에서 빠르게 API 성능을 평가하고자 할 때 특히 유용합니다.

또한, Locust로 작성된 테스트 스크립트는 Python 코드로 구성되어 있기 때문에, GitHub과 같은 원격 저장소에 코드를 올려두면 팀원이나 다른 개발자들이 언제든지 손쉽게 해당 스크립트를 클론하고, 필요한 부하 테스트를 즉시 실행할 수 있습니다. 이는 협업 환경에서의 테스트 과정을 매우 효율적으로 만들어 줍니다. 팀원들은 최신의 테스트 스크립트를 공유받아, 실시간으로 테스트 결과를 확인하고 성능 개선 작업을 진행할 수 있습니다.

이와 더불어, Locust는 실시간으로 테스트 결과를 웹 인터페이스를 통해 제공합니다. 사용자는 웹 브라우저를 통해 테스트의 진행 상황을 모니터링하고, 성능 지표를 실시간으로 확인할 수 있습니다. 이는 테스트 과정에서의 직관적인 데이터 분석과 신속한 의사 결정을 가능하게 합니다.

요약하자면, Locust는 설치와 사용이 쉬우며, 로컬 환경에서의 빠른 구동 능력으로 인해 개발자가 신속하게 성능 테스트를 수행할 수 있게 해줍니다. Python 기반의 스크립트 작성 방식은 깃헙과 같은 원격 저장소를 통한 협업에 매우 유리하며, 이로 인해 개발 프로세스의 효율성과 속도를 크게 향상시킬 수 있습니다.

## Locust Dashboard

### Start new load test

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust_005.png)

Start new load test 버튼을 클릭하여 새로운 부하 테스트를 시작할 수 있습니다. 이 버튼을 클릭하면 다음과 같은 옵션을 설정할 수 있는 팝업 창이 나타납니다.

* Number of Users
    * 정의: 테스트에서 동시에 시뮬레이션할 가상 사용자의 총 수입니다.
    * 목적: 애플리케이션이 동시에 처리할 수 있는 사용자 수를 설정하여, 애플리케이션의 동시 사용자 처리 능력을 테스트합니다.
* Ramp Up (일반적으로 Ramp Up 시간을 의미하며, Locust에서는 Spawn Rate으로 표현될 수 있음)
    * 정의: 테스트 시작부터 설정된 전체 사용자 수에 도달하기까지의 시간 또는 사용자가 점진적으로 증가하는 속도입니다.
    * 목적: 사용자 수가 점진적으로 증가하는 상황을 모델링하여, 애플리케이션이 사용자 증가 속도에 어떻게 대응하는지 평가합니다.

### Statistics

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust_001.png)

Statistics 섹션은 현재 진행 중인 테스트의 실시간 통계를 제공합니다. 이 테이블에는 각 요청 유형별로 세분화된 데이터가 포함되어 있으며, 다음과 같은 정보를 확인할 수 있습니다:

* Name: 요청의 이름이나 경로를 나타냅니다.
* requests: 해당 요청이 몇 번 실행되었는지 보여줍니다.
* failures: 요청 실패 횟수를 나타냅니다.
* Median response time: 응답 시간의 중앙값(밀리초 단위)을 보여줍니다. 이는 모든 요청 중간에 위치하는 응답 시간을 의미합니다.
* Average response time: 평균 응답 시간을 나타냅니다.
* Min/Max response time: 관찰된 최소 및 최대 응답 시간입니다.
* Request per second: 초당 요청 수를 보여줍니다.

### Charts

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust_002.png)

Charts 섹션은 테스트 동안 수집된 데이터를 그래프 형태로 시각화합니다. 이 차트는 테스트의 진행에 따라 동적으로 업데이트되며, 주로 다음과 같은 정보를 제공합니다.

* Requests per second (RPS): 시간에 따른 초당 요청 수의 변화를 나타냅니다.
* Response times: 다양한 응답 시간(평균, 최소, 최대)을 시간 경과에 따라 보여줍니다.
* Number of users: 시간에 따른 사용자 수의 변화를 보여줍니다.

### Download Data

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust_003.png)

Download Data 메뉴는 테스트 결과를 다운로드할 수 있는 옵션을 제공합니다. 테스트의 통계 및 차트 데이터를 CSV 파일 형식으로 내보낼 수 있으며, 이는 보다 심층적인 분석이나 문서화, 또는 다른 팀 구성원과의 공유를 위해 사용될 수 있습니다.

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust_004.png)

특히 Download the Report 메뉴를 통해 테스트 결과를 HTML 형식으로 다운로드할 수 있습니다. 이 HTML 리포트는 테스트의 요약 정보와 세부 통계, 그리고 차트 데이터를 포함하고 있으며, 테스트 결과를 보다 시각적으로 표현할 수 있습니다. 이 리포트는 테스트 결과를 문서화하거나, 다른 팀원과 공유할 때 유용하게 사용될 수 있습니다.

### Local Performance Test

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust_006.png)

로컬 환경에서의 성능 테스트 결과, 루프백 네트워크를 통해 2,500 TPS를 달성했습니다. 이는 로컬 환경의 특성을 활용한 결과이며, 실제 운영 환경에서는 성능이 다를 수 있지만, 로컬에서 쉽게 높은 TPS를 달성할 수 있다는 점을 시사합니다.

## 정리

Locust는 사용의 용이성과 빠른 테스트 실행 능력으로 개발자에게 탁월한 부하 테스트 도구를 제공합니다. Python 기반으로 간단한 설치와 함께, 누구나 쉽게 테스트를 시작할 수 있으며, 이는 빠른 성능 평가와 적시의 개선으로 이어집니다.

원격 저장소를 통한 테스트 스크립트 공유는 팀 내 협업을 강화하며, 모든 팀원이 필요한 테스트를 쉽게 실행할 수 있게 합니다. 이러한 접근성은 테스트의 재사용성을 높이고, 개발 프로세스의 효율성을 개선합니다.

Locust는 단순한 테스트 도구를 넘어, 성능 모니터링과 개선을 위한 협업의 핵심이 됩니다. 이를 통해, 사용자에게 최적의 경험을 제공하는 애플리케이션을 구축할 수 있습니다.

이 글을 읽기 전에, [Locust 성능 테스트 도구 소개](https://cheese10yun.github.io/locust-part-1/)를 먼저 확인해 보시는 것이 좋습니다. 이를 통해 Locust의 기본적인 사용법과 개념을 이해하신 후, 본 글에서 다루는 보다 심화된 사용 방법과 전략에 쉽게 접근하실 수 있습니다.

## on_start 및 on_stop 메서드

```python
class OrderApiTest(HttpUser):
    def on_start(self):
        self.client.post("/login")
    
    def on_stop(self):
        self.client.post("/logout")
```

`on_start`와 `on_stop` 메서드는 사용자의 세션 시작과 종료 시 특정 작업을 실행하는 데 사용됩니다. 로그인과 로그아웃 외에도, 사용자가 시나리오를 시작하기 전에 필요한 데이터를 세팅하거나, 시나리오 종료 후 사용한 리소스를 정리하는 데 사용할 수 있습니다. 예를 들어, 시나리오 시작 시 특정 API를 호출하여 필요한 설정을 하거나, 시나리오가 끝난 후 생성된 데이터를 삭제하는 등의 작업이 있을 수 있습니다. 이러한 메서드를 통해 테스트의 사전 준비와 후처리를 자동화할 수 있습니다. `on_start`는 사용자가 시작될 때 호출되며, `on_stop`은 사용자가 종료될 때 호출됩니다. 강제로 loucst를 종료하면 `on_stop` 메서드가 호출되지 않습니다.

## @task를 이용한 API 요청 비율 조정

```python

class Advance(HttpUser):
    ...
    @task(3)
    def getOrder(self):
        ...
        self.client.get(
            "/api/v1/orders",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/orders"
        )

    @task(1)
    def getShop(self):
        ...
        self.client.get(
            "/api/v1/shops",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/shops"
        )

```

![](https://raw.githubusercontent.com/cheese10yun/blog-sample/master/locust/imag/locust-1-1.png)

`@task` 데코레이터는 Locust에서 작업의 실행 빈도나 우선순위를 지정하는 데 사용됩니다. 숫자를 인자로 제공함으로써, 특정 작업이 다른 작업들에 비해 상대적으로 얼마나 자주 실행될지 결정할 수 있습니다. 예를 들어, `@task(3)`은 해당 작업이 같은 TaskSet 내 다른 `@task(1)` 작업보다 세 배 더 많이 실행됨을 의미합니다. 이를 통해 실제 사용자 행동을 더 잘 모방한 부하 테스트 시나리오를 구성할 수 있습니다.

## 순차적 TaskSets로 워크플로우 시뮬레이션

```python
class OrderTaskSet(TaskSet):

    @task
    def getOrder(self):
        ...
        self.client.get(
            "/api/v1/orders",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/orders"
        )

    @task
    def getShop(self):
        ...
        self.client.get(
            "/api/v1/shops",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/shops"
        )

class OrderTask(HttpUser):
    wait_time = constant_pacing(2)  # 최소 10초 간격으로 작업 실행이 보장되도록 대기 시간 설정
    host = "http://localhost:8080"  # 테스트 대상 호스트 주소 지정

    tasks = [OrderTaskSet]
```

순차적 TaskSets를 사용하는 워크플로우 시뮬레이션은 사용자가 실제 애플리케이션을 사용할 때의 행동 순서를 모방하는 데 사용됩니다. 이 방식에서는 TaskSet 클래스 내에서 각각의 `@task` 함수가 사용자의 다음 동작을 시뮬레이션합니다. 이 예제에서는 `OrderTaskSet` 내의 `getOrder`와 `getShop`이 동일한 비율로 실행되며, 사용자는 이 두 작업 사이를 순차적으로, 또는 랜덤으로 전환하면서 진행할 수 있습니다. `constant_pacing` 설정을 통해 각 작업 사이의 실행 간격을 조절함으로써, 실제 사용자 경험에 더 가까운 테스트 환경을 구성할 수 있습니다. 자세한 내용은 [Locust 공식 문서](https://docs.locust.io/en/stable/tasksets.html#tasksets)를 참조하세요.

공식 문서는 정확한 비율의 작업 호출을 달성하기 위해 루프와 제어문 사용을 권장합니다. `@task`를 이용한 간단한 호출 비율 조정은 대략적인 작업 순서에 적합하지만, 정확한 작업 순서가 필요한 경우, 공식 문서의 권장 사항을 따르는 것이 더 바람직합니다.

## 맞춤형 부하 형태 시뮬레이션

```python
class Advance(HttpUser):
    wait_time = constant(1)  # 모든 요청 사이에 3초의 고정된 대기 시간 설정
    host = "http://localhost:8080"  # 테스트 대상 호스트 주소 지정

    @task
    def getOrder(self):
        ...
        self.client.get(
            "/api/v1/orders",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/orders"
        )

    @task
    def getShop(self):
        ...
        self.client.get(
            "/api/v1/shops",
            headers = { "Content-Type": "application/json" },
            params = params,
            name = "/api/v1/shops"
        )



# 사용자 정의 부하 모양을 정의하는 LoadTestShape 클래스
class CustomShape(LoadTestShape):
    time_limit = 600  # 부하 테스트의 총 시간 한계 설정
    spawn_rate = 20  # 초당 새로운 사용자를 생성하는 속도 설정

    def tick(self):
        run_time = self.get_run_time()  # 현재 실행 시간 가져오기

        if run_time < self.time_limit:
            # 실행 시간에 따라 사용자 수 증가
            user_count = run_time // 10
            return (user_count, self.spawn_rate)

        return None  # 시간 한계를 넘으면 테스트 종료
```

위 코드는 Locust를 사용한 사용자 정의 부하 테스트 시나리오를 설정하는 예시입니다. 테스트 시작부터 시간이 600초(10분)에 이르기까지 실행 시간에 따라 사용자 수를 점진적으로 증가시킵니다. `tick` 함수는 현재 실행 시간을 기반으로 사용자 수를 결정하고, 실행 시간이 10초마다 사용자 수를 1명씩 증가시키는 로직을 포함하고 있습니다. 시간 한계에 도달하면, 즉 실행 시간이 600초를 초과하면, 테스트는 자동으로 종료됩니다. 이를 통해 초기 단계에서는 부하가 점점 증가하다가 설정된 시간이 지나면 테스트가 종료되는 시나리오를 구현할 수 있습니다.

## 정리

사용자 세션 시작과 종료에 필요한 동작을 자동화하는 `on_start`와 `on_stop` 메서드, 다양한 API 요청의 실행 비율을 조절하는 `@task`, 실제 사용자 워크플로우 시뮬레이션에 유용한 순차적 `TaskSets`, 그리고 테스트 동안 사용자 부하를 동적으로 조절할 수 있는 맞춤형 부하 형태 `CustomShape`에 대해 설명합니다. 이 방법들은 Locust를 활용하여 보다 실제적이고 유연한 성능 테스트를 구현하는 데 도움을 줍니다.

## ???



| 항목                            | 설명                                                                               |
|-------------------------------|----------------------------------------------------------------------------------|
| **totalConnections**          | 연결 풀에 존재하는 전체 연결의 수입니다. 이 값은 `activeConnections`와 `idleConnections`의 합과 동일합니다.   |
| **activeConnections**         | 현재 사용 중인 연결의 수입니다. 이 연결들은 실제로 애플리케이션에서 쿼리를 실행하는 데 사용되고 있는 상태입니다.                 |
| **idleConnections**           | 현재 유휴 상태에 있는(즉, 사용되지 않고 대기 중인) 연결의 수입니다. 이 연결들은 요청이 있을 때 다시 사용될 수 있도록 준비되어 있습니다. |
| **threadsAwaitingConnection** | 사용 가능한 연결을 기다리는 스레드의 수입니다. 모든 연결이 사용 중일 때 새 연결 요청이 들어오면 대기 중인 스레드 수가 증가합니다.      |
| **maxLifetime**               | 각 연결이 풀에서 유지될 수 있는 최대 시간입니다. 이 시간이 초과되면 연결은 자동으로 폐기되고 새 연결이 생성됩니다. 단위는 밀리초입니다.   |
| **maximumPoolSize**           | 풀에 허용되는 최대 연결 수입니다. 이 값은 연결 풀에서 관리할 수 있는 연결의 최대 수를 정의합니다.                        |
| **connectionTimeout**         | 새로운 연결을 얻기 위해 스레드가 대기할 수 있는 최대 시간입니다. 이 시간이 초과되면 예외가 발생합니다. 단위는 밀리초입니다.          |
| **validationTimeout**         | 풀에서 연결이 유효한지 검사할 때 기다리는 최대 시간입니다. 연결을 사용하기 전에 이 시간 동안 유효성을 검사합니다. 단위는 밀리초입니다.    |
| **idleTimeout**               | 연결이 유휴 상태로 유지될 수 있는 최대 시간입니다. 이 시간이 지나면 유휴 상태인 연결은 풀에서 제거됩니다. 단위는 밀리초입니다.        |


```kotlin
val targetDataSource = dataSource.unwrap(HikariDataSource::class.java)
val hikariDataSource = targetDataSource as HikariDataSource
val hikariPoolMXBean = hikariDataSource.hikariPoolMXBean
val hikariConfigMXBean = hikariDataSource.hikariConfigMXBean

val trimIndent =
    """
    totalConnections : ${hikariPoolMXBean.totalConnections}
    activeConnections : ${hikariPoolMXBean.activeConnections}
    idleConnections : ${hikariPoolMXBean.idleConnections}
    threadsAwaitingConnection : ${hikariPoolMXBean.threadsAwaitingConnection}
    maxLifetime : ${hikariConfigMXBean.maxLifetime}
    maximumPoolSize : ${hikariConfigMXBean.maximumPoolSize}
    connectionTimeout : ${hikariConfigMXBean.connectionTimeout}
    validationTimeout : ${hikariConfigMXBean.validationTimeout}
    idleTimeout : ${hikariConfigMXBean.idleTimeout}
    """.trimIndent()

log.info(trimIndent)
```

```
totalConnections : 50
activeConnections : 50
idleConnections : 0
threadsAwaitingConnection : 32
```

